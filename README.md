ABSTRACT
Emotions play a fundamental role in human communication, influencing how we express and interpret intentions, thoughts, and states of mind. Understanding the emotional content of spoken language is vital for improving human-computer interaction, enhancing the user experience, and enabling applications in various domains, including healthcare, education, customer service, and entertainment. The goal is to determine the emotional state of a speaker, such as happiness, anger, sadness etc. from speech patterns, such as pitch and rhythm.

This project demonstrates the integration of a SPEECH EMOTION RECOGNITION using CNN and librosa library. The website allows users upload a audio file or record lively and displays emotion detected.


prerequisites
1.python
2.librosa
3.soundfile
4.numpy
5.sklearn
6.keras
7.pickle
8.django

install pip before installing prerequesties

Step 1: run the CNN_M8_goodone.ipynb file inside the SER_TRAINING folder - it is the code for training SER ml model
Step 2: run the manage.py file inside the SER_WEBPAGE directory. - it opens the web
